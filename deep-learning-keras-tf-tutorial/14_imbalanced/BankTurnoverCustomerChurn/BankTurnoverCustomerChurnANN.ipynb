{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ed424ce-8c23-4f1c-94fc-e5d4f06426fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb6eed7-9701-4a0b-88c9-e14e1d95c73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>1962</td>\n",
       "      <td>15668472</td>\n",
       "      <td>Ritchie</td>\n",
       "      <td>705</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>177799.83</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79886.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>4612</td>\n",
       "      <td>15710553</td>\n",
       "      <td>Yin</td>\n",
       "      <td>555</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>142055.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79134.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1015</td>\n",
       "      <td>15585961</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>496</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>199505.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>2290</td>\n",
       "      <td>15789097</td>\n",
       "      <td>Keeley</td>\n",
       "      <td>644</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44965.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>6479</td>\n",
       "      <td>15573348</td>\n",
       "      <td>Maclean</td>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>102050.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3769.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId  Surname  CreditScore Geography  Gender  Age  \\\n",
       "1961       1962    15668472  Ritchie          705     Spain  Female   24   \n",
       "4611       4612    15710553      Yin          555   Germany    Male   48   \n",
       "1014       1015    15585961   Talbot          496     Spain  Female   43   \n",
       "2289       2290    15789097   Keeley          644    France    Male   48   \n",
       "6478       6479    15573348  Maclean          850    France    Male   35   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "1961       5  177799.83              2          0               0   \n",
       "4611       3  142055.41              2          0               1   \n",
       "1014       3       0.00              2          0               1   \n",
       "2289       8       0.00              2          0               1   \n",
       "6478       9  102050.47              1          1               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "1961         79886.06       0  \n",
       "4611         79134.78       0  \n",
       "1014        199505.53       0  \n",
       "2289         44965.54       1  \n",
       "6478          3769.71       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6e0c52-1c1f-47f2-bd33-0eba7ab49cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2ba8d-5f90-486a-9607-a3c0dff075ac",
   "metadata": {},
   "source": [
    "# DROP Columns which are of no use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd129a6-a0ea-4b45-9da2-d2add9dabf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1663c3f4-0a56-4b7c-8288-ea46ccf09655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db71bf7-b937-4780-835e-181dc166a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique column values\n",
    "def print_unique_col_value(df):\n",
    "    for col in df:\n",
    "        print(f\"{col} : {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d4223c-4096-4ad0-8dae-87ae8c5e7e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Geography : ['France' 'Spain' 'Germany']\n",
      "Gender : ['Female' 'Male']\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_value(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a292f94-670e-47db-ab8d-d18f536d23c4",
   "metadata": {},
   "source": [
    "# ONE HOT ENCODING CATEGORICAL VALUES Geography Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5e647ce-8de2-4cb7-8c7d-59b76975e6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "474385e5-1e65-48be-a0b2-40b58baf5023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_France',\n",
       "       'Geography_Germany', 'Geography_Spain', 'Gender_Female', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ae952b9-002d-4b6f-b4aa-f82894916bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [619 608 502 699 850 645 822 376 501 684 528 497 476 549 635 616 653 587\n",
      " 726 732 636 510 669 846 577 756 571 574 411 591 533 553 520 722 475 490\n",
      " 804 582 472 465 556 834 660 776 829 637 550 698 585 788 655 601 656 725\n",
      " 511 614 742 687 555 603 751 581 735 661 675 738 813 657 604 519 664 678\n",
      " 757 416 665 777 543 506 493 652 750 729 646 647 808 524 769 730 515 773\n",
      " 814 710 413 623 670 622 785 605 479 685 538 562 721 628 668 828 674 625\n",
      " 432 770 758 795 686 789 589 461 584 579 663 682 793 691 485 650 754 535\n",
      " 716 539 706 586 631 717 800 683 704 615 667 484 480 578 512 606 597 778\n",
      " 514 525 715 580 807 521 759 516 711 618 643 671 689 620 676 572 695 592\n",
      " 567 694 547 594 673 610 767 763 712 703 662 659 523 772 545 634 739 771\n",
      " 681 544 696 766 727 693 557 531 498 651 791 733 811 707 714 782 775 799\n",
      " 602 744 588 747 583 627 731 629 438 642 806 474 559 429 680 749 734 644\n",
      " 626 649 805 718 840 630 654 762 568 613 522 737 648 443 640 540 460 593\n",
      " 801 611 802 745 483 690 492 709 705 560 752 701 537 487 596 702 486 724\n",
      " 548 464 790 534 748 494 590 468 509 818 816 536 753 774 621 569 658 798\n",
      " 641 542 692 639 765 570 638 599 632 779 527 564 833 504 842 508 417 598\n",
      " 741 607 761 848 546 439 755 760 526 713 700 666 566 495 688 612 477 427\n",
      " 839 819 720 459 503 624 529 563 482 796 445 746 786 554 672 787 499 844\n",
      " 450 815 838 803 736 633 600 679 517 792 743 488 421 841 708 507 505 456\n",
      " 435 561 518 565 728 784 552 609 764 697 723 551 444 719 496 541 830 812\n",
      " 677 420 595 617 809 500 826 434 513 478 797 363 399 463 780 452 575 837\n",
      " 794 824 428 823 781 849 489 431 457 768 831 359 820 573 576 558 817 449\n",
      " 440 415 821 530 350 446 425 740 481 783 358 845 451 458 469 423 404 836\n",
      " 473 835 466 491 351 827 843 365 532 414 453 471 401 810 832 470 447 422\n",
      " 825 430 436 426 408 847 418 437 410 454 407 455 462 386 405 383 395 467\n",
      " 433 442 424 448 441 367 412 382 373 419]\n",
      "Age : [42 41 39 43 44 50 29 27 31 24 34 25 35 45 58 32 38 46 36 33 40 51 61 49\n",
      " 37 19 66 56 26 21 55 75 22 30 28 65 48 52 57 73 47 54 72 20 67 79 62 53\n",
      " 80 59 68 23 60 70 63 64 18 82 69 74 71 76 77 88 85 84 78 81 92 83]\n",
      "Tenure : [ 2  1  8  7  4  6  3 10  5  9  0]\n",
      "Balance : [     0.    83807.86 159660.8  ...  57369.61  75075.31 130142.79]\n",
      "NumOfProducts : [1 3 2 4]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [101348.88 112542.58 113931.57 ...  42085.58  92888.52  38190.78]\n",
      "Exited : [1 0]\n",
      "Geography_France : [1 0]\n",
      "Geography_Germany : [0 1]\n",
      "Geography_Spain : [0 1]\n",
      "Gender_Female : [1 0]\n",
      "Gender_Male : [0 1]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_value(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33376ccb-120b-4fe7-a598-ecf3ccf28597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore            int64\n",
       "Age                    int64\n",
       "Tenure                 int64\n",
       "Balance              float64\n",
       "NumOfProducts          int64\n",
       "HasCrCard              int64\n",
       "IsActiveMember         int64\n",
       "EstimatedSalary      float64\n",
       "Exited                 int64\n",
       "Geography_France       int64\n",
       "Geography_Germany      int64\n",
       "Geography_Spain        int64\n",
       "Gender_Female          int64\n",
       "Gender_Male            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a403eaad-5d3c-4a6e-8e68-81cbf3420b20",
   "metadata": {},
   "source": [
    "# Conver boolean type to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e7ed83b-fc57-4de1-8e02-cfae7288e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_columns = ['Geography_France', 'Geography_Germany', 'Geography_Spain', 'Gender_Female', 'Gender_Male']\n",
    "\n",
    "for col in boolean_columns:\n",
    "    df1[col] = df1[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f1e16-04c1-4ed5-bc4b-aa285fbf4ff1",
   "metadata": {},
   "source": [
    "# Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31e6cd4f-bb99-4fea-8692-d894a7881f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = MinMaxScaler()\n",
    "df1[columns_to_scale] = scaler.fit_transform(df1[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b429789-7fdb-422b-bb6b-43ce665aa631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore : [0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
      " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
      " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
      " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
      " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
      " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
      " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
      " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
      " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
      " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
      " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
      " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
      " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
      " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
      " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
      " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
      " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
      " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
      " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
      " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
      " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
      " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
      " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
      " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
      " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
      " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
      " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
      " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
      " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
      " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
      " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
      " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
      " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
      " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
      " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
      " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
      " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
      " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
      " 0.124 0.064 0.046 0.138]\n",
      "Age : [0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
      " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
      " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
      " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
      " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
      " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
      " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
      " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
      " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
      " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
      " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
      " 0.81081081 0.85135135 1.         0.87837838]\n",
      "Tenure : [0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
      "Balance : [0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
      "NumOfProducts : [0.         0.66666667 0.33333333 1.        ]\n",
      "HasCrCard : [1 0]\n",
      "IsActiveMember : [1 0]\n",
      "EstimatedSalary : [0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
      "Exited : [1 0]\n",
      "Geography_France : [1 0]\n",
      "Geography_Germany : [0 1]\n",
      "Geography_Spain : [0 1]\n",
      "Gender_Female : [1 0]\n",
      "Gender_Male : [0 1]\n"
     ]
    }
   ],
   "source": [
    "print_unique_col_value(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ca039-b470-4347-b6d2-74787b4906ba",
   "metadata": {},
   "source": [
    "# Check if any entry is null for an specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46e4440a-9d5e-448d-9c48-feb8b76b4c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "9995    False\n",
       "9996    False\n",
       "9997    False\n",
       "9998    False\n",
       "9999    False\n",
       "Name: EstimatedSalary, Length: 10000, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df1.EstimatedSalary, errors='coerce').isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3c31e-6ef3-4bbd-af39-a33949062662",
   "metadata": {},
   "source": [
    "# Create test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a6a6135-1d13-472d-b9cf-f5b2b30c4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dd7039f-92ee-40ca-8449-19b22da33366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 13), (10000,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c51897a-a50a-4eb4-82f4-a23119fad658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4fdc323-35f6-4f87-8ff5-e2ec9900fb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 13), (2000, 13), (8000,), (2000,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199c056-6b8e-45da-b605-f3bc4ae1362c",
   "metadata": {},
   "source": [
    "# Define the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff457e9e-193a-4959-b18a-9db3ff89fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def ANN(X_train, y_train, X_test, y_test, loss):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(13, input_dim=13, activation='relu'),\n",
    "        keras.layers.Dense(10,  activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2f212c78-0c2d-48ab-a8b4-4c9ef82d5ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 745us/step - loss: 0.5174 - accuracy: 0.7960\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 699us/step - loss: 0.4735 - accuracy: 0.7962\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.4582 - accuracy: 0.7968\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.4415 - accuracy: 0.8070\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.4313 - accuracy: 0.8155\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.4237 - accuracy: 0.8195\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.4180 - accuracy: 0.8234\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.4128 - accuracy: 0.8215\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.4072 - accuracy: 0.8236\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.4022 - accuracy: 0.8313\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 780us/step - loss: 0.3978 - accuracy: 0.8307\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.3922 - accuracy: 0.8324\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.3879 - accuracy: 0.8359\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.3846 - accuracy: 0.8376\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 809us/step - loss: 0.3803 - accuracy: 0.8404\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 701us/step - loss: 0.3770 - accuracy: 0.8419\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3739 - accuracy: 0.8430\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 880us/step - loss: 0.3722 - accuracy: 0.8479\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.3687 - accuracy: 0.8482\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.3664 - accuracy: 0.8484\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 723us/step - loss: 0.3639 - accuracy: 0.8503\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.3600 - accuracy: 0.8520\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.3587 - accuracy: 0.8533\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.3550 - accuracy: 0.8540\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3530 - accuracy: 0.8555\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.3522 - accuracy: 0.8565\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 905us/step - loss: 0.3519 - accuracy: 0.8549\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 871us/step - loss: 0.3511 - accuracy: 0.8575\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 754us/step - loss: 0.3486 - accuracy: 0.8590\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3482 - accuracy: 0.8569\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.3474 - accuracy: 0.8571\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.3469 - accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.3466 - accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.3457 - accuracy: 0.8596\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.3446 - accuracy: 0.8591\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.3442 - accuracy: 0.8597\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 700us/step - loss: 0.3439 - accuracy: 0.8581\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.3442 - accuracy: 0.8599\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.3442 - accuracy: 0.8583\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.3438 - accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3423 - accuracy: 0.8591\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 833us/step - loss: 0.3418 - accuracy: 0.8609\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.3414 - accuracy: 0.8589\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.3426 - accuracy: 0.8587\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.3418 - accuracy: 0.8604\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 734us/step - loss: 0.3412 - accuracy: 0.8605\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 730us/step - loss: 0.3407 - accuracy: 0.8601\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3404 - accuracy: 0.8595\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.3404 - accuracy: 0.8610\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.3399 - accuracy: 0.8612\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.3398 - accuracy: 0.8600\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3394 - accuracy: 0.8618\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3391 - accuracy: 0.8618\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 748us/step - loss: 0.3404 - accuracy: 0.8606\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3400 - accuracy: 0.8591\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3404 - accuracy: 0.8596\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3385 - accuracy: 0.8615\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3391 - accuracy: 0.8600\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 708us/step - loss: 0.3388 - accuracy: 0.8631\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 702us/step - loss: 0.3377 - accuracy: 0.8631\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 709us/step - loss: 0.3388 - accuracy: 0.8616\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.3378 - accuracy: 0.8612\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 811us/step - loss: 0.3376 - accuracy: 0.8622\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3383 - accuracy: 0.8612\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 720us/step - loss: 0.3369 - accuracy: 0.8619\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 785us/step - loss: 0.3378 - accuracy: 0.8637\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 703us/step - loss: 0.3372 - accuracy: 0.8627\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3367 - accuracy: 0.8624\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 706us/step - loss: 0.3374 - accuracy: 0.8608\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.3366 - accuracy: 0.8626\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.3363 - accuracy: 0.8622\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 728us/step - loss: 0.3363 - accuracy: 0.8612\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3374 - accuracy: 0.8625\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 705us/step - loss: 0.3360 - accuracy: 0.8601\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8639\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 764us/step - loss: 0.3365 - accuracy: 0.8621\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 855us/step - loss: 0.3354 - accuracy: 0.8633\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.3353 - accuracy: 0.8627\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3360 - accuracy: 0.8625\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3347 - accuracy: 0.8633\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 0s 727us/step - loss: 0.3361 - accuracy: 0.8630\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 756us/step - loss: 0.3342 - accuracy: 0.8645\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.3348 - accuracy: 0.8610\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 713us/step - loss: 0.3348 - accuracy: 0.8631\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 740us/step - loss: 0.3352 - accuracy: 0.8626\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 789us/step - loss: 0.3338 - accuracy: 0.8650\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 737us/step - loss: 0.3339 - accuracy: 0.8646\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 770us/step - loss: 0.3339 - accuracy: 0.8622\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 731us/step - loss: 0.3338 - accuracy: 0.8621\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.3328 - accuracy: 0.8650\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 714us/step - loss: 0.3339 - accuracy: 0.8620\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 834us/step - loss: 0.3337 - accuracy: 0.8627\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.3334 - accuracy: 0.8648\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.3325 - accuracy: 0.8626\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.3336 - accuracy: 0.8635\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 712us/step - loss: 0.3328 - accuracy: 0.8659\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 719us/step - loss: 0.3330 - accuracy: 0.8635\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.3335 - accuracy: 0.8640\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 715us/step - loss: 0.3317 - accuracy: 0.8622\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 710us/step - loss: 0.3336 - accuracy: 0.8634\n",
      "63/63 [==============================] - 0s 715us/step - loss: 0.3361 - accuracy: 0.8665\n",
      "[0.33612650632858276, 0.8665000200271606]\n",
      "63/63 [==============================] - 0s 562us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92      1593\n",
      "           1       0.78      0.48      0.59       407\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.72      0.76      2000\n",
      "weighted avg       0.86      0.87      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cc892f6-305e-46e1-88ef-4e38185b414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89ffb9-f0da-48ab-bfa0-dc92ed4dfddc",
   "metadata": {},
   "source": [
    "# Method1: Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7b99dd0-c0b4-400b-aae7-26cc8e762dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0_maj, count_class_1_min = df1.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a8acee1-7518-490c-b72f-cdd71fafa7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0_maj, count_class_1_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15b7590f-50e1-4806-b2fa-42d7779a625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_class_0_maj = df1[df1['Exited'] == 0]\n",
    "df1_class_1_min = df1[df1['Exited'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70c77d19-ded8-4d52-953f-ac682741e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 14), (2037, 14))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_class_0_maj.shape, df1_class_0_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c19a05e-6479-4317-9169-60a960e057d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nder sample majority calss and place to a new data frame\n",
    "df1_class_0_under = df1_class_0_maj.sample(count_class_1_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b878da8e-7367-4a53-ae84-0eda237c169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commbine undersampled and minority to create the new data samples\n",
    "df1_under = pd.concat([df1_class_0_under,df1_class_1_min]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0d9b4db8-aa25-45b5-87cf-f8df169f13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1_under.drop('Exited', axis='columns')\n",
    "y = df1_under['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4932e1ab-38c8-4416-8bdf-51f9fcad64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the train and test sampled from the new balanced data samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a74bb3c-b6e1-43af-8149-9f5487afc674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 851us/step - loss: 0.6944 - accuracy: 0.4778\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 739us/step - loss: 0.6887 - accuracy: 0.5603\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 768us/step - loss: 0.6811 - accuracy: 0.5901\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.6653 - accuracy: 0.6214\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.6415 - accuracy: 0.6496\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 738us/step - loss: 0.6251 - accuracy: 0.6527\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 746us/step - loss: 0.6171 - accuracy: 0.6637\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 771us/step - loss: 0.6092 - accuracy: 0.6729\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 788us/step - loss: 0.6028 - accuracy: 0.6726\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 796us/step - loss: 0.5958 - accuracy: 0.6833\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.5907 - accuracy: 0.6947\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.5839 - accuracy: 0.6956\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 751us/step - loss: 0.5774 - accuracy: 0.6978\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 764us/step - loss: 0.5712 - accuracy: 0.6999\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 795us/step - loss: 0.5644 - accuracy: 0.7094\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 785us/step - loss: 0.5570 - accuracy: 0.7156\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 813us/step - loss: 0.5487 - accuracy: 0.7214\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 801us/step - loss: 0.5393 - accuracy: 0.7343\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.5299 - accuracy: 0.7447\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 800us/step - loss: 0.5205 - accuracy: 0.7515\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 891us/step - loss: 0.5138 - accuracy: 0.7576\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 774us/step - loss: 0.5053 - accuracy: 0.7616\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 748us/step - loss: 0.4987 - accuracy: 0.7613\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.4951 - accuracy: 0.7643\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7594\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 966us/step - loss: 0.4876 - accuracy: 0.7689\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 807us/step - loss: 0.4854 - accuracy: 0.7653\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4826 - accuracy: 0.7720\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4813 - accuracy: 0.7686\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 732us/step - loss: 0.4804 - accuracy: 0.7708\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 738us/step - loss: 0.4791 - accuracy: 0.7686\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 739us/step - loss: 0.4786 - accuracy: 0.7705\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4772 - accuracy: 0.7720\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4776 - accuracy: 0.7656\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 746us/step - loss: 0.4770 - accuracy: 0.7680\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4757 - accuracy: 0.7693\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4748 - accuracy: 0.7702\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4742 - accuracy: 0.7726\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 904us/step - loss: 0.4743 - accuracy: 0.7717\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 812us/step - loss: 0.4741 - accuracy: 0.7699\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4733 - accuracy: 0.7732\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 768us/step - loss: 0.4743 - accuracy: 0.7647\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.4724 - accuracy: 0.7689\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 733us/step - loss: 0.4723 - accuracy: 0.7736\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4724 - accuracy: 0.7736\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 748us/step - loss: 0.4721 - accuracy: 0.7674\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4714 - accuracy: 0.7720\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4707 - accuracy: 0.7708\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 739us/step - loss: 0.4712 - accuracy: 0.7732\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 742us/step - loss: 0.4711 - accuracy: 0.7680\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 746us/step - loss: 0.4701 - accuracy: 0.7732\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4701 - accuracy: 0.7711\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 742us/step - loss: 0.4698 - accuracy: 0.7785\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 992us/step - loss: 0.4705 - accuracy: 0.7723\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 736us/step - loss: 0.4690 - accuracy: 0.7729\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 732us/step - loss: 0.4705 - accuracy: 0.7714\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 733us/step - loss: 0.4698 - accuracy: 0.7757\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4698 - accuracy: 0.7708\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 732us/step - loss: 0.4691 - accuracy: 0.7748\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 737us/step - loss: 0.4683 - accuracy: 0.7739\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.4687 - accuracy: 0.7717\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4696 - accuracy: 0.7763\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 737us/step - loss: 0.4684 - accuracy: 0.7736\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4683 - accuracy: 0.7699\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4682 - accuracy: 0.7717\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4677 - accuracy: 0.7763\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.4681 - accuracy: 0.7748\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 733us/step - loss: 0.4681 - accuracy: 0.7754\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 736us/step - loss: 0.4674 - accuracy: 0.7726\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.4680 - accuracy: 0.7751\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 731us/step - loss: 0.4665 - accuracy: 0.7705\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 734us/step - loss: 0.4676 - accuracy: 0.7757\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4667 - accuracy: 0.7748\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4676 - accuracy: 0.7705\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 734us/step - loss: 0.4655 - accuracy: 0.7748\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.4660 - accuracy: 0.7778\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4673 - accuracy: 0.7736\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 744us/step - loss: 0.4656 - accuracy: 0.7757\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4665 - accuracy: 0.7742\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 744us/step - loss: 0.4646 - accuracy: 0.7782\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.4673 - accuracy: 0.7751\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 730us/step - loss: 0.4657 - accuracy: 0.7717\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4668 - accuracy: 0.7772\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 730us/step - loss: 0.4661 - accuracy: 0.7757\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4657 - accuracy: 0.7705\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4652 - accuracy: 0.7757\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 731us/step - loss: 0.4665 - accuracy: 0.7714\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 732us/step - loss: 0.4659 - accuracy: 0.7757\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 734us/step - loss: 0.4646 - accuracy: 0.7745\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 737us/step - loss: 0.4638 - accuracy: 0.7739\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 739us/step - loss: 0.4645 - accuracy: 0.7788\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 738us/step - loss: 0.4639 - accuracy: 0.7775\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 748us/step - loss: 0.4652 - accuracy: 0.7766\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 744us/step - loss: 0.4639 - accuracy: 0.7785\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4636 - accuracy: 0.7775\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4639 - accuracy: 0.7702\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4640 - accuracy: 0.7736\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4632 - accuracy: 0.7757\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 972us/step - loss: 0.4641 - accuracy: 0.7760\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 807us/step - loss: 0.4635 - accuracy: 0.7775\n",
      "26/26 [==============================] - 0s 861us/step - loss: 0.4921 - accuracy: 0.7521\n",
      "[0.4920552372932434, 0.7521472573280334]\n",
      "26/26 [==============================] - 0s 607us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       407\n",
      "           1       0.75      0.75      0.75       408\n",
      "\n",
      "    accuracy                           0.75       815\n",
      "   macro avg       0.75      0.75      0.75       815\n",
      "weighted avg       0.75      0.75      0.75       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds_und = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ae247-3d31-4e58-8345-daf735fedb21",
   "metadata": {},
   "source": [
    "# Method2: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5465d2f4-875d-46d0-a10d-0c78febfb046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_class_1_oversampled = df1_class_1_min.sample(count_class_0_maj, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e62f91e1-3e84-4700-beed-e8705f693662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_over = pd.concat([df1_class_1_oversampled, df1_class_0_maj], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2eb34d69-857f-4814-92e2-c945d24ac460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1_over.drop('Exited', axis='columns')\n",
    "y = df1_over['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce05ab3f-fd1c-4883-968a-019de56a61fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff20f2ed-0b1d-45d3-a036-b330e835d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 758us/step - loss: 0.6700 - accuracy: 0.5790\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.6250 - accuracy: 0.6546\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 0s 726us/step - loss: 0.5916 - accuracy: 0.6925\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 0s 721us/step - loss: 0.5703 - accuracy: 0.7075\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.5603 - accuracy: 0.7132\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 0s 848us/step - loss: 0.5508 - accuracy: 0.7211\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 0s 813us/step - loss: 0.5390 - accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.5250 - accuracy: 0.7417\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.5104 - accuracy: 0.7513\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 0s 722us/step - loss: 0.4981 - accuracy: 0.7600\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 0s 720us/step - loss: 0.4910 - accuracy: 0.7642\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 0s 722us/step - loss: 0.4846 - accuracy: 0.7686\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4816 - accuracy: 0.7671\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 0s 725us/step - loss: 0.4778 - accuracy: 0.7703\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 0s 724us/step - loss: 0.4758 - accuracy: 0.7701\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 0s 721us/step - loss: 0.4740 - accuracy: 0.7711\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 0s 754us/step - loss: 0.4718 - accuracy: 0.7732\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4697 - accuracy: 0.7723\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 0s 816us/step - loss: 0.4686 - accuracy: 0.7750\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4671 - accuracy: 0.7744\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4661 - accuracy: 0.7753\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 0s 742us/step - loss: 0.4649 - accuracy: 0.7772\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 0s 845us/step - loss: 0.4637 - accuracy: 0.7763\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 0s 721us/step - loss: 0.4632 - accuracy: 0.7756\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 0s 783us/step - loss: 0.4619 - accuracy: 0.7758\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 0s 800us/step - loss: 0.4605 - accuracy: 0.7792\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 0s 799us/step - loss: 0.4610 - accuracy: 0.7767\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 0s 886us/step - loss: 0.4600 - accuracy: 0.7768\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 0s 878us/step - loss: 0.4589 - accuracy: 0.7770\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 0s 786us/step - loss: 0.4580 - accuracy: 0.7791\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 0s 829us/step - loss: 0.4585 - accuracy: 0.7777\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4574 - accuracy: 0.7808\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 0s 742us/step - loss: 0.4568 - accuracy: 0.7812\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 0s 734us/step - loss: 0.4557 - accuracy: 0.7803\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4558 - accuracy: 0.7788\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4556 - accuracy: 0.7789\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 0s 741us/step - loss: 0.4545 - accuracy: 0.7815\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 0s 780us/step - loss: 0.4540 - accuracy: 0.7823\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 0s 790us/step - loss: 0.4521 - accuracy: 0.7816\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4519 - accuracy: 0.7829\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 0s 735us/step - loss: 0.4517 - accuracy: 0.7813\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 0s 778us/step - loss: 0.4514 - accuracy: 0.7841\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 0s 807us/step - loss: 0.4509 - accuracy: 0.7818\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 0s 749us/step - loss: 0.4507 - accuracy: 0.7831\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4496 - accuracy: 0.7852\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 0s 734us/step - loss: 0.4492 - accuracy: 0.7859\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4483 - accuracy: 0.7829\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 0s 770us/step - loss: 0.4479 - accuracy: 0.7850\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 0s 750us/step - loss: 0.4471 - accuracy: 0.7858\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 0s 773us/step - loss: 0.4464 - accuracy: 0.7862\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 0s 783us/step - loss: 0.4460 - accuracy: 0.7873\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 0s 742us/step - loss: 0.4462 - accuracy: 0.7869\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 0s 797us/step - loss: 0.4450 - accuracy: 0.7854\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 0s 768us/step - loss: 0.4448 - accuracy: 0.7893\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4445 - accuracy: 0.7881\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4438 - accuracy: 0.7910\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 0s 725us/step - loss: 0.4431 - accuracy: 0.7902\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 0s 898us/step - loss: 0.4427 - accuracy: 0.7898\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4428 - accuracy: 0.7903\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4427 - accuracy: 0.7900\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7914\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7896\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 0s 915us/step - loss: 0.4418 - accuracy: 0.7916\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 0s 910us/step - loss: 0.4417 - accuracy: 0.7914\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 0s 955us/step - loss: 0.4410 - accuracy: 0.7915\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 0s 898us/step - loss: 0.4400 - accuracy: 0.7911\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4416 - accuracy: 0.7940\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4402 - accuracy: 0.7922\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 0s 739us/step - loss: 0.4408 - accuracy: 0.7929\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 0s 739us/step - loss: 0.4395 - accuracy: 0.7924\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4395 - accuracy: 0.7932\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 0s 818us/step - loss: 0.4401 - accuracy: 0.7917\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4396 - accuracy: 0.7918\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4388 - accuracy: 0.7929\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4387 - accuracy: 0.7955\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 0s 726us/step - loss: 0.4383 - accuracy: 0.7939\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4386 - accuracy: 0.7930\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 0s 737us/step - loss: 0.4388 - accuracy: 0.7921\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 0s 738us/step - loss: 0.4379 - accuracy: 0.7948\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 0s 774us/step - loss: 0.4380 - accuracy: 0.7943\n",
      "Epoch 81/100\n",
      "399/399 [==============================] - 0s 819us/step - loss: 0.4384 - accuracy: 0.7927\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 0s 746us/step - loss: 0.4377 - accuracy: 0.7925\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 0s 736us/step - loss: 0.4385 - accuracy: 0.7913\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 0s 806us/step - loss: 0.4384 - accuracy: 0.7954\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 0s 745us/step - loss: 0.4378 - accuracy: 0.7926\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4366 - accuracy: 0.7944\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4385 - accuracy: 0.7922\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4367 - accuracy: 0.7968\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 0s 786us/step - loss: 0.4374 - accuracy: 0.7944\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 0s 801us/step - loss: 0.4370 - accuracy: 0.7930\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 0s 949us/step - loss: 0.4375 - accuracy: 0.7940\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 0s 818us/step - loss: 0.4368 - accuracy: 0.7930\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 0s 795us/step - loss: 0.4367 - accuracy: 0.7963\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 0s 751us/step - loss: 0.4366 - accuracy: 0.7943\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 0s 811us/step - loss: 0.4368 - accuracy: 0.7949\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 0s 743us/step - loss: 0.4362 - accuracy: 0.7973\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 0s 734us/step - loss: 0.4374 - accuracy: 0.7932\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 0s 759us/step - loss: 0.4357 - accuracy: 0.7958\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 0s 811us/step - loss: 0.4365 - accuracy: 0.7943\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 0s 778us/step - loss: 0.4358 - accuracy: 0.7962\n",
      "100/100 [==============================] - 0s 698us/step - loss: 0.4477 - accuracy: 0.7894\n",
      "[0.44774332642555237, 0.7893911004066467]\n",
      "100/100 [==============================] - 0s 574us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1593\n",
      "           1       0.79      0.78      0.79      1593\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.79      0.79      0.79      3186\n",
      "weighted avg       0.79      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds_over = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb42d40-d263-40e0-9688-bd2fc8498160",
   "metadata": {},
   "source": [
    "# Method 3: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe70976b-7162-46c8-9e55-20c418bca5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns')\n",
    "y = df1['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "70d61096-bf8d-48dc-b7e2-9e1c651d9a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote =SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d996b32-899e-4acb-b997-622cd0e668c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "17c70785-5e62-4a7f-988e-e0c303aee6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 742us/step - loss: 0.6505 - accuracy: 0.6149\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 0s 722us/step - loss: 0.5911 - accuracy: 0.6885\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 0s 743us/step - loss: 0.5619 - accuracy: 0.7118\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.5458 - accuracy: 0.7257\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 0s 724us/step - loss: 0.5296 - accuracy: 0.7384\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 0s 723us/step - loss: 0.5103 - accuracy: 0.7516\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 0s 743us/step - loss: 0.4937 - accuracy: 0.7586\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4817 - accuracy: 0.7651\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 0s 720us/step - loss: 0.4723 - accuracy: 0.7683\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 0s 742us/step - loss: 0.4668 - accuracy: 0.7749\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4627 - accuracy: 0.7769\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 0s 807us/step - loss: 0.4607 - accuracy: 0.7786\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 0s 751us/step - loss: 0.4580 - accuracy: 0.7797\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4565 - accuracy: 0.7805\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 0s 720us/step - loss: 0.4549 - accuracy: 0.7799\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 0s 736us/step - loss: 0.4520 - accuracy: 0.7827\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4509 - accuracy: 0.7817\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4496 - accuracy: 0.7810\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 0s 822us/step - loss: 0.4488 - accuracy: 0.7840\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 0s 795us/step - loss: 0.4478 - accuracy: 0.7852\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4474 - accuracy: 0.7857\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 0s 724us/step - loss: 0.4451 - accuracy: 0.7878\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4457 - accuracy: 0.7873\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4434 - accuracy: 0.7849\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4436 - accuracy: 0.7885\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 0s 814us/step - loss: 0.4426 - accuracy: 0.7859\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4419 - accuracy: 0.7889\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 0s 740us/step - loss: 0.4409 - accuracy: 0.7907\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 0s 765us/step - loss: 0.4416 - accuracy: 0.7874\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 0s 741us/step - loss: 0.4415 - accuracy: 0.7895\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 0s 744us/step - loss: 0.4396 - accuracy: 0.7900\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 0s 771us/step - loss: 0.4397 - accuracy: 0.7903\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 0s 770us/step - loss: 0.4396 - accuracy: 0.7889\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4392 - accuracy: 0.7923\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 0s 737us/step - loss: 0.4379 - accuracy: 0.7918\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4382 - accuracy: 0.7939\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4372 - accuracy: 0.7938\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 0s 741us/step - loss: 0.4368 - accuracy: 0.7954\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 0s 809us/step - loss: 0.4372 - accuracy: 0.7925\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 0s 742us/step - loss: 0.4364 - accuracy: 0.7925\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 0s 792us/step - loss: 0.4355 - accuracy: 0.7929\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 0s 768us/step - loss: 0.4356 - accuracy: 0.7947\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 0s 735us/step - loss: 0.4357 - accuracy: 0.7940\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4351 - accuracy: 0.7925\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4348 - accuracy: 0.7961\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 0s 735us/step - loss: 0.4354 - accuracy: 0.7933\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4339 - accuracy: 0.7959\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4347 - accuracy: 0.7954\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 0s 736us/step - loss: 0.4341 - accuracy: 0.7951\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 0s 725us/step - loss: 0.4334 - accuracy: 0.7951\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 0s 740us/step - loss: 0.4338 - accuracy: 0.7928\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 0s 870us/step - loss: 0.4320 - accuracy: 0.7941\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 0s 811us/step - loss: 0.4326 - accuracy: 0.7952\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - 0s 746us/step - loss: 0.4332 - accuracy: 0.7959\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4331 - accuracy: 0.7957\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 0s 740us/step - loss: 0.4323 - accuracy: 0.7962\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 0s 749us/step - loss: 0.4316 - accuracy: 0.7969\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 0s 739us/step - loss: 0.4315 - accuracy: 0.7995\n",
      "Epoch 59/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4313 - accuracy: 0.7973\n",
      "Epoch 60/100\n",
      "399/399 [==============================] - 0s 745us/step - loss: 0.4308 - accuracy: 0.7967\n",
      "Epoch 61/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4322 - accuracy: 0.7973\n",
      "Epoch 62/100\n",
      "399/399 [==============================] - 0s 739us/step - loss: 0.4299 - accuracy: 0.7968\n",
      "Epoch 63/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4304 - accuracy: 0.7976\n",
      "Epoch 64/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4303 - accuracy: 0.7977\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4301 - accuracy: 0.7981\n",
      "Epoch 66/100\n",
      "399/399 [==============================] - 0s 734us/step - loss: 0.4304 - accuracy: 0.7951\n",
      "Epoch 67/100\n",
      "399/399 [==============================] - 0s 810us/step - loss: 0.4292 - accuracy: 0.7975\n",
      "Epoch 68/100\n",
      "399/399 [==============================] - 0s 736us/step - loss: 0.4290 - accuracy: 0.7981\n",
      "Epoch 69/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4296 - accuracy: 0.7987\n",
      "Epoch 70/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4287 - accuracy: 0.7997\n",
      "Epoch 71/100\n",
      "399/399 [==============================] - 0s 735us/step - loss: 0.4289 - accuracy: 0.7984\n",
      "Epoch 72/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4282 - accuracy: 0.7989\n",
      "Epoch 73/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4271 - accuracy: 0.7999\n",
      "Epoch 74/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4281 - accuracy: 0.8005\n",
      "Epoch 75/100\n",
      "399/399 [==============================] - 0s 727us/step - loss: 0.4288 - accuracy: 0.7977\n",
      "Epoch 76/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4283 - accuracy: 0.7982\n",
      "Epoch 77/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4269 - accuracy: 0.7989\n",
      "Epoch 78/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4269 - accuracy: 0.7994\n",
      "Epoch 79/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4268 - accuracy: 0.7995\n",
      "Epoch 80/100\n",
      "399/399 [==============================] - 0s 728us/step - loss: 0.4270 - accuracy: 0.7994\n",
      "Epoch 81/100\n",
      "399/399 [==============================] - 0s 734us/step - loss: 0.4264 - accuracy: 0.7979\n",
      "Epoch 82/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4264 - accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "399/399 [==============================] - 0s 819us/step - loss: 0.4264 - accuracy: 0.8008\n",
      "Epoch 84/100\n",
      "399/399 [==============================] - 0s 736us/step - loss: 0.4264 - accuracy: 0.7966\n",
      "Epoch 85/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4252 - accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "399/399 [==============================] - 0s 738us/step - loss: 0.4268 - accuracy: 0.7977\n",
      "Epoch 87/100\n",
      "399/399 [==============================] - 0s 803us/step - loss: 0.4256 - accuracy: 0.8024\n",
      "Epoch 88/100\n",
      "399/399 [==============================] - 0s 740us/step - loss: 0.4260 - accuracy: 0.7988\n",
      "Epoch 89/100\n",
      "399/399 [==============================] - 0s 732us/step - loss: 0.4251 - accuracy: 0.8008\n",
      "Epoch 90/100\n",
      "399/399 [==============================] - 0s 730us/step - loss: 0.4242 - accuracy: 0.7998\n",
      "Epoch 91/100\n",
      "399/399 [==============================] - 0s 731us/step - loss: 0.4248 - accuracy: 0.7995\n",
      "Epoch 92/100\n",
      "399/399 [==============================] - 0s 746us/step - loss: 0.4254 - accuracy: 0.7962\n",
      "Epoch 93/100\n",
      "399/399 [==============================] - 0s 832us/step - loss: 0.4250 - accuracy: 0.7982\n",
      "Epoch 94/100\n",
      "399/399 [==============================] - 0s 813us/step - loss: 0.4249 - accuracy: 0.7991\n",
      "Epoch 95/100\n",
      "399/399 [==============================] - 0s 814us/step - loss: 0.4257 - accuracy: 0.7988\n",
      "Epoch 96/100\n",
      "399/399 [==============================] - 0s 806us/step - loss: 0.4237 - accuracy: 0.7995\n",
      "Epoch 97/100\n",
      "399/399 [==============================] - 0s 923us/step - loss: 0.4234 - accuracy: 0.8015\n",
      "Epoch 98/100\n",
      "399/399 [==============================] - 0s 790us/step - loss: 0.4232 - accuracy: 0.8020\n",
      "Epoch 99/100\n",
      "399/399 [==============================] - 0s 733us/step - loss: 0.4232 - accuracy: 0.7984\n",
      "Epoch 100/100\n",
      "399/399 [==============================] - 0s 729us/step - loss: 0.4236 - accuracy: 0.8009\n",
      "100/100 [==============================] - 0s 708us/step - loss: 0.4203 - accuracy: 0.8016\n",
      "[0.42027410864830017, 0.8016321659088135]\n",
      "100/100 [==============================] - 0s 584us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1593\n",
      "           1       0.81      0.79      0.80      1593\n",
      "\n",
      "    accuracy                           0.80      3186\n",
      "   macro avg       0.80      0.80      0.80      3186\n",
      "weighted avg       0.80      0.80      0.80      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds_smote = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52af15-ca1a-4f5b-8a89-33656488df24",
   "metadata": {},
   "source": [
    "# Method4: Use of Ensemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "da384234-8499-4633-947d-259160322584",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop('Exited', axis='columns') \n",
    "y = df1['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9ad0c574-a267-493e-ad75-b84cfcee4216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    6370\n",
       "1    1630\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4999a275-4fca-4216-9005-2a13320a59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c8d8994-f9aa-4d02-b8c4-9dfa3804e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.Exited.value_counts()\n",
    "df2_class0_maj = df2[df2['Exited'] == 0]\n",
    "df2_class1_min = df2[df2['Exited'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4193fd-70f6-495c-8289-64953554224f",
   "metadata": {},
   "source": [
    "## create a funtion that will return the train and test set base on index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "110208dd-c264-4030-b3a4-31336f59ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_maj, df_min, start, end):\n",
    "    df_train = pd.concat([df_maj[start:end], df_min], axis=0)\n",
    "    \n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "287ce3ad-f157-4ae0-a7f4-aeb1db198f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 850us/step - loss: 0.6922 - accuracy: 0.5058\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 728us/step - loss: 0.6701 - accuracy: 0.6206\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 728us/step - loss: 0.6435 - accuracy: 0.6482\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.6225 - accuracy: 0.6641\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 769us/step - loss: 0.6127 - accuracy: 0.6718\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 742us/step - loss: 0.6044 - accuracy: 0.6770\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.5962 - accuracy: 0.6853\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 824us/step - loss: 0.5873 - accuracy: 0.6917\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 837us/step - loss: 0.5797 - accuracy: 0.6994\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.5712 - accuracy: 0.7046\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 785us/step - loss: 0.5615 - accuracy: 0.7184\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 791us/step - loss: 0.5517 - accuracy: 0.7252\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.5434 - accuracy: 0.7285\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 762us/step - loss: 0.5326 - accuracy: 0.7374\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 797us/step - loss: 0.5252 - accuracy: 0.7426\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 983us/step - loss: 0.5193 - accuracy: 0.7479\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 760us/step - loss: 0.5130 - accuracy: 0.7525\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 768us/step - loss: 0.5102 - accuracy: 0.7475\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 770us/step - loss: 0.5046 - accuracy: 0.7586\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 779us/step - loss: 0.5015 - accuracy: 0.7610\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 783us/step - loss: 0.4985 - accuracy: 0.7583\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 794us/step - loss: 0.4966 - accuracy: 0.7567\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 831us/step - loss: 0.4941 - accuracy: 0.7595\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 734us/step - loss: 0.4942 - accuracy: 0.7629\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7598\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 786us/step - loss: 0.4901 - accuracy: 0.7632\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 786us/step - loss: 0.4894 - accuracy: 0.7638\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 774us/step - loss: 0.4887 - accuracy: 0.7675\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.4871 - accuracy: 0.7660\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 773us/step - loss: 0.4874 - accuracy: 0.7638\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.4853 - accuracy: 0.7638\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4853 - accuracy: 0.7653\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 796us/step - loss: 0.4848 - accuracy: 0.7632\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 804us/step - loss: 0.4842 - accuracy: 0.7684\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 807us/step - loss: 0.4846 - accuracy: 0.7681\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 798us/step - loss: 0.4825 - accuracy: 0.7681\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 790us/step - loss: 0.4823 - accuracy: 0.7678\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4821 - accuracy: 0.7678\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4810 - accuracy: 0.7663\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.4810 - accuracy: 0.7626\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 773us/step - loss: 0.4808 - accuracy: 0.7681\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 801us/step - loss: 0.4797 - accuracy: 0.7653\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4800 - accuracy: 0.7656\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4796 - accuracy: 0.7675\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 801us/step - loss: 0.4801 - accuracy: 0.7663\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 846us/step - loss: 0.4787 - accuracy: 0.7699\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 737us/step - loss: 0.4787 - accuracy: 0.7666\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4784 - accuracy: 0.7709\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 863us/step - loss: 0.4786 - accuracy: 0.7718\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 878us/step - loss: 0.4790 - accuracy: 0.7684\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 783us/step - loss: 0.4787 - accuracy: 0.7675\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 813us/step - loss: 0.4769 - accuracy: 0.7687\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 782us/step - loss: 0.4781 - accuracy: 0.7696\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 791us/step - loss: 0.4764 - accuracy: 0.7715\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7718\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 798us/step - loss: 0.4768 - accuracy: 0.7693\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.4760 - accuracy: 0.7675\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4770 - accuracy: 0.7663\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4772 - accuracy: 0.7672\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4760 - accuracy: 0.7715\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4771 - accuracy: 0.7736\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4774 - accuracy: 0.7699\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4767 - accuracy: 0.7681\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4753 - accuracy: 0.7706\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4766 - accuracy: 0.7690\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4744 - accuracy: 0.7755\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4732 - accuracy: 0.7721\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 749us/step - loss: 0.4736 - accuracy: 0.7715\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 785us/step - loss: 0.4731 - accuracy: 0.7724\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 751us/step - loss: 0.4736 - accuracy: 0.7730\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4727 - accuracy: 0.7706\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4742 - accuracy: 0.7739\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.4741 - accuracy: 0.7724\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 740us/step - loss: 0.4725 - accuracy: 0.7752\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 798us/step - loss: 0.4727 - accuracy: 0.7736\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 752us/step - loss: 0.4725 - accuracy: 0.7761\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 749us/step - loss: 0.4719 - accuracy: 0.7745\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.4716 - accuracy: 0.7755\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 751us/step - loss: 0.4713 - accuracy: 0.7730\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4711 - accuracy: 0.7761\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 785us/step - loss: 0.4715 - accuracy: 0.7727\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4704 - accuracy: 0.7724\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4698 - accuracy: 0.7736\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 760us/step - loss: 0.4718 - accuracy: 0.7773\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 766us/step - loss: 0.4706 - accuracy: 0.7745\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 736us/step - loss: 0.4699 - accuracy: 0.7736\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4699 - accuracy: 0.7730\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.4702 - accuracy: 0.7733\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 748us/step - loss: 0.4695 - accuracy: 0.7745\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 759us/step - loss: 0.4698 - accuracy: 0.7745\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4690 - accuracy: 0.7745\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 735us/step - loss: 0.4675 - accuracy: 0.7742\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4690 - accuracy: 0.7752\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4690 - accuracy: 0.7755\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 764us/step - loss: 0.4670 - accuracy: 0.7733\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 746us/step - loss: 0.4700 - accuracy: 0.7755\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 796us/step - loss: 0.4668 - accuracy: 0.7752\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 762us/step - loss: 0.4664 - accuracy: 0.7810\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 749us/step - loss: 0.4668 - accuracy: 0.7727\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4671 - accuracy: 0.7730\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7570\n",
      "[0.49226659536361694, 0.7570000290870667]\n",
      "63/63 [==============================] - 0s 615us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      1593\n",
      "           1       0.45      0.79      0.57       407\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.69      0.77      0.70      2000\n",
      "weighted avg       0.83      0.76      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0_maj, df2_class1_min, 0, 1630)\n",
    "y_preds_en1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9c8e7c35-3667-4602-90c2-68222e7cc680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 878us/step - loss: 0.6689 - accuracy: 0.5908\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 806us/step - loss: 0.6540 - accuracy: 0.6187\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 899us/step - loss: 0.6412 - accuracy: 0.6319\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 791us/step - loss: 0.6296 - accuracy: 0.6460\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 796us/step - loss: 0.6194 - accuracy: 0.6580\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 802us/step - loss: 0.6101 - accuracy: 0.6684\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 731us/step - loss: 0.6002 - accuracy: 0.6801\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.5919 - accuracy: 0.6877\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 799us/step - loss: 0.5841 - accuracy: 0.6923\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 762us/step - loss: 0.5765 - accuracy: 0.7009\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 804us/step - loss: 0.5709 - accuracy: 0.7095\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 777us/step - loss: 0.5641 - accuracy: 0.7113\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 826us/step - loss: 0.5570 - accuracy: 0.7193\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 752us/step - loss: 0.5519 - accuracy: 0.7258\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 779us/step - loss: 0.5462 - accuracy: 0.7347\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 775us/step - loss: 0.5425 - accuracy: 0.7350\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 739us/step - loss: 0.5386 - accuracy: 0.7387\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.5312 - accuracy: 0.7420\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 787us/step - loss: 0.5261 - accuracy: 0.7509\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 978us/step - loss: 0.5202 - accuracy: 0.7577\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.5157 - accuracy: 0.7620\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 772us/step - loss: 0.5117 - accuracy: 0.7601\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 769us/step - loss: 0.5069 - accuracy: 0.7629\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 800us/step - loss: 0.5031 - accuracy: 0.7672\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 802us/step - loss: 0.5004 - accuracy: 0.7635\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 775us/step - loss: 0.4977 - accuracy: 0.7656\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 771us/step - loss: 0.4952 - accuracy: 0.7650\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 785us/step - loss: 0.4928 - accuracy: 0.7687\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4910 - accuracy: 0.7739\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 807us/step - loss: 0.4888 - accuracy: 0.7656\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 813us/step - loss: 0.4893 - accuracy: 0.7669\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 742us/step - loss: 0.4875 - accuracy: 0.7678\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7690\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.4859 - accuracy: 0.7718\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 769us/step - loss: 0.4849 - accuracy: 0.7681\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 776us/step - loss: 0.4841 - accuracy: 0.7669\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 786us/step - loss: 0.4820 - accuracy: 0.7724\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.4839 - accuracy: 0.7672\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 805us/step - loss: 0.4806 - accuracy: 0.7699\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 820us/step - loss: 0.4805 - accuracy: 0.7712\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 739us/step - loss: 0.4798 - accuracy: 0.7706\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4785 - accuracy: 0.7702\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 800us/step - loss: 0.4775 - accuracy: 0.7706\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 781us/step - loss: 0.4787 - accuracy: 0.7715\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 782us/step - loss: 0.4786 - accuracy: 0.7721\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.4783 - accuracy: 0.7715\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 773us/step - loss: 0.4768 - accuracy: 0.7752\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 789us/step - loss: 0.4760 - accuracy: 0.7718\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 798us/step - loss: 0.4758 - accuracy: 0.7718\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 773us/step - loss: 0.4747 - accuracy: 0.7724\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 862us/step - loss: 0.4743 - accuracy: 0.7761\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 777us/step - loss: 0.4755 - accuracy: 0.7696\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 777us/step - loss: 0.4746 - accuracy: 0.7693\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 814us/step - loss: 0.4769 - accuracy: 0.7730\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.4726 - accuracy: 0.7724\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 762us/step - loss: 0.4737 - accuracy: 0.7715\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7764\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 795us/step - loss: 0.4720 - accuracy: 0.7764\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 794us/step - loss: 0.4718 - accuracy: 0.7721\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.4697 - accuracy: 0.7807\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 807us/step - loss: 0.4714 - accuracy: 0.7752\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 760us/step - loss: 0.4709 - accuracy: 0.7739\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4689 - accuracy: 0.7758\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4698 - accuracy: 0.7727\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4688 - accuracy: 0.7752\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 774us/step - loss: 0.4701 - accuracy: 0.7819\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 812us/step - loss: 0.4697 - accuracy: 0.7788\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 744us/step - loss: 0.4684 - accuracy: 0.7742\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 759us/step - loss: 0.4673 - accuracy: 0.7764\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.4685 - accuracy: 0.7739\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4677 - accuracy: 0.7816\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4671 - accuracy: 0.7745\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 759us/step - loss: 0.4684 - accuracy: 0.7758\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 766us/step - loss: 0.4660 - accuracy: 0.7755\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 825us/step - loss: 0.4671 - accuracy: 0.7798\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 872us/step - loss: 0.4666 - accuracy: 0.7721\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 757us/step - loss: 0.4675 - accuracy: 0.7764\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4670 - accuracy: 0.7767\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 762us/step - loss: 0.4660 - accuracy: 0.7770\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4646 - accuracy: 0.7782\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 749us/step - loss: 0.4646 - accuracy: 0.7742\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4646 - accuracy: 0.7816\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 766us/step - loss: 0.4656 - accuracy: 0.7767\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.4645 - accuracy: 0.7782\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 761us/step - loss: 0.4639 - accuracy: 0.7810\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4641 - accuracy: 0.7745\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.4636 - accuracy: 0.7791\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.4642 - accuracy: 0.7788\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 757us/step - loss: 0.4636 - accuracy: 0.7782\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 762us/step - loss: 0.4633 - accuracy: 0.7745\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 786us/step - loss: 0.4621 - accuracy: 0.7831\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.4619 - accuracy: 0.7807\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 780us/step - loss: 0.4637 - accuracy: 0.7831\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 760us/step - loss: 0.4620 - accuracy: 0.7773\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 770us/step - loss: 0.4617 - accuracy: 0.7767\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 755us/step - loss: 0.4613 - accuracy: 0.7825\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 758us/step - loss: 0.4620 - accuracy: 0.7825\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.4628 - accuracy: 0.7816\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.4617 - accuracy: 0.7776\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.4619 - accuracy: 0.7791\n",
      "63/63 [==============================] - 0s 703us/step - loss: 0.4694 - accuracy: 0.7725\n",
      "[0.4694176912307739, 0.7724999785423279]\n",
      "63/63 [==============================] - 0s 608us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84      1593\n",
      "           1       0.46      0.78      0.58       407\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.70      0.78      0.71      2000\n",
      "weighted avg       0.84      0.77      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0_maj, df2_class1_min, 1630, 2*1630)\n",
    "y_preds_en2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c74c4b0b-b822-4001-9bc1-6120c2c5eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 834us/step - loss: 0.6773 - accuracy: 0.5876\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 768us/step - loss: 0.6580 - accuracy: 0.6410\n",
      "Epoch 3/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.6393 - accuracy: 0.6530\n",
      "Epoch 4/100\n",
      "102/102 [==============================] - 0s 782us/step - loss: 0.6233 - accuracy: 0.6689\n",
      "Epoch 5/100\n",
      "102/102 [==============================] - 0s 780us/step - loss: 0.6107 - accuracy: 0.6766\n",
      "Epoch 6/100\n",
      "102/102 [==============================] - 0s 746us/step - loss: 0.6026 - accuracy: 0.6806\n",
      "Epoch 7/100\n",
      "102/102 [==============================] - 0s 807us/step - loss: 0.5947 - accuracy: 0.6876\n",
      "Epoch 8/100\n",
      "102/102 [==============================] - 0s 788us/step - loss: 0.5878 - accuracy: 0.6925\n",
      "Epoch 9/100\n",
      "102/102 [==============================] - 0s 797us/step - loss: 0.5825 - accuracy: 0.6990\n",
      "Epoch 10/100\n",
      "102/102 [==============================] - 0s 773us/step - loss: 0.5746 - accuracy: 0.7097\n",
      "Epoch 11/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7119\n",
      "Epoch 12/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.5605 - accuracy: 0.7183\n",
      "Epoch 13/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.5543 - accuracy: 0.7281\n",
      "Epoch 14/100\n",
      "102/102 [==============================] - 0s 777us/step - loss: 0.5482 - accuracy: 0.7272\n",
      "Epoch 15/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.5430 - accuracy: 0.7340\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 912us/step - loss: 0.5382 - accuracy: 0.7386\n",
      "Epoch 17/100\n",
      "102/102 [==============================] - 0s 836us/step - loss: 0.5354 - accuracy: 0.7370\n",
      "Epoch 18/100\n",
      "102/102 [==============================] - 0s 749us/step - loss: 0.5294 - accuracy: 0.7429\n",
      "Epoch 19/100\n",
      "102/102 [==============================] - 0s 838us/step - loss: 0.5257 - accuracy: 0.7465\n",
      "Epoch 20/100\n",
      "102/102 [==============================] - 0s 815us/step - loss: 0.5224 - accuracy: 0.7465\n",
      "Epoch 21/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.5203 - accuracy: 0.7493\n",
      "Epoch 22/100\n",
      "102/102 [==============================] - 0s 757us/step - loss: 0.5172 - accuracy: 0.7545\n",
      "Epoch 23/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.5135 - accuracy: 0.7527\n",
      "Epoch 24/100\n",
      "102/102 [==============================] - 0s 763us/step - loss: 0.5119 - accuracy: 0.7533\n",
      "Epoch 25/100\n",
      "102/102 [==============================] - 0s 774us/step - loss: 0.5082 - accuracy: 0.7554\n",
      "Epoch 26/100\n",
      "102/102 [==============================] - 0s 774us/step - loss: 0.5056 - accuracy: 0.7564\n",
      "Epoch 27/100\n",
      "102/102 [==============================] - 0s 770us/step - loss: 0.5027 - accuracy: 0.7573\n",
      "Epoch 28/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.5009 - accuracy: 0.7607\n",
      "Epoch 29/100\n",
      "102/102 [==============================] - 0s 764us/step - loss: 0.4991 - accuracy: 0.7585\n",
      "Epoch 30/100\n",
      "102/102 [==============================] - 0s 757us/step - loss: 0.4953 - accuracy: 0.7650\n",
      "Epoch 31/100\n",
      "102/102 [==============================] - 0s 782us/step - loss: 0.4954 - accuracy: 0.7564\n",
      "Epoch 32/100\n",
      "102/102 [==============================] - 0s 744us/step - loss: 0.4918 - accuracy: 0.7637\n",
      "Epoch 33/100\n",
      "102/102 [==============================] - 0s 802us/step - loss: 0.4910 - accuracy: 0.7653\n",
      "Epoch 34/100\n",
      "102/102 [==============================] - 0s 769us/step - loss: 0.4873 - accuracy: 0.7656\n",
      "Epoch 35/100\n",
      "102/102 [==============================] - 0s 779us/step - loss: 0.4868 - accuracy: 0.7625\n",
      "Epoch 36/100\n",
      "102/102 [==============================] - 0s 968us/step - loss: 0.4862 - accuracy: 0.7683\n",
      "Epoch 37/100\n",
      "102/102 [==============================] - 0s 796us/step - loss: 0.4837 - accuracy: 0.7659\n",
      "Epoch 38/100\n",
      "102/102 [==============================] - 0s 760us/step - loss: 0.4818 - accuracy: 0.7686\n",
      "Epoch 39/100\n",
      "102/102 [==============================] - 0s 752us/step - loss: 0.4815 - accuracy: 0.7699\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.4797 - accuracy: 0.7720\n",
      "Epoch 41/100\n",
      "102/102 [==============================] - 0s 789us/step - loss: 0.4778 - accuracy: 0.7723\n",
      "Epoch 42/100\n",
      "102/102 [==============================] - 0s 742us/step - loss: 0.4769 - accuracy: 0.7723\n",
      "Epoch 43/100\n",
      "102/102 [==============================] - 0s 772us/step - loss: 0.4769 - accuracy: 0.7696\n",
      "Epoch 44/100\n",
      "102/102 [==============================] - 0s 820us/step - loss: 0.4754 - accuracy: 0.7705\n",
      "Epoch 45/100\n",
      "102/102 [==============================] - 0s 742us/step - loss: 0.4748 - accuracy: 0.7720\n",
      "Epoch 46/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7723\n",
      "Epoch 47/100\n",
      "102/102 [==============================] - 0s 752us/step - loss: 0.4721 - accuracy: 0.7742\n",
      "Epoch 48/100\n",
      "102/102 [==============================] - 0s 770us/step - loss: 0.4718 - accuracy: 0.7705\n",
      "Epoch 49/100\n",
      "102/102 [==============================] - 0s 795us/step - loss: 0.4710 - accuracy: 0.7745\n",
      "Epoch 50/100\n",
      "102/102 [==============================] - 0s 778us/step - loss: 0.4717 - accuracy: 0.7736\n",
      "Epoch 51/100\n",
      "102/102 [==============================] - 0s 799us/step - loss: 0.4700 - accuracy: 0.7748\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 748us/step - loss: 0.4706 - accuracy: 0.7763\n",
      "Epoch 53/100\n",
      "102/102 [==============================] - 0s 760us/step - loss: 0.4689 - accuracy: 0.7772\n",
      "Epoch 54/100\n",
      "102/102 [==============================] - 0s 799us/step - loss: 0.4684 - accuracy: 0.7714\n",
      "Epoch 55/100\n",
      "102/102 [==============================] - 0s 768us/step - loss: 0.4681 - accuracy: 0.7757\n",
      "Epoch 56/100\n",
      "102/102 [==============================] - 0s 756us/step - loss: 0.4660 - accuracy: 0.7736\n",
      "Epoch 57/100\n",
      "102/102 [==============================] - 0s 813us/step - loss: 0.4655 - accuracy: 0.7745\n",
      "Epoch 58/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4664 - accuracy: 0.7797\n",
      "Epoch 59/100\n",
      "102/102 [==============================] - 0s 780us/step - loss: 0.4658 - accuracy: 0.7720\n",
      "Epoch 60/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.4648 - accuracy: 0.7772\n",
      "Epoch 61/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4645 - accuracy: 0.7751\n",
      "Epoch 62/100\n",
      "102/102 [==============================] - 0s 765us/step - loss: 0.4634 - accuracy: 0.7782\n",
      "Epoch 63/100\n",
      "102/102 [==============================] - 0s 773us/step - loss: 0.4632 - accuracy: 0.7754\n",
      "Epoch 64/100\n",
      "102/102 [==============================] - 0s 790us/step - loss: 0.4624 - accuracy: 0.7782\n",
      "Epoch 65/100\n",
      "102/102 [==============================] - 0s 785us/step - loss: 0.4619 - accuracy: 0.7785\n",
      "Epoch 66/100\n",
      "102/102 [==============================] - 0s 764us/step - loss: 0.4638 - accuracy: 0.7757\n",
      "Epoch 67/100\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4631 - accuracy: 0.7785\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 795us/step - loss: 0.4620 - accuracy: 0.7812\n",
      "Epoch 69/100\n",
      "102/102 [==============================] - 0s 750us/step - loss: 0.4610 - accuracy: 0.7785\n",
      "Epoch 70/100\n",
      "102/102 [==============================] - 0s 982us/step - loss: 0.4617 - accuracy: 0.7818\n",
      "Epoch 71/100\n",
      "102/102 [==============================] - 0s 927us/step - loss: 0.4605 - accuracy: 0.7772\n",
      "Epoch 72/100\n",
      "102/102 [==============================] - 0s 736us/step - loss: 0.4591 - accuracy: 0.7794\n",
      "Epoch 73/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.4594 - accuracy: 0.7791\n",
      "Epoch 74/100\n",
      "102/102 [==============================] - 0s 751us/step - loss: 0.4586 - accuracy: 0.7812\n",
      "Epoch 75/100\n",
      "102/102 [==============================] - 0s 764us/step - loss: 0.4595 - accuracy: 0.7803\n",
      "Epoch 76/100\n",
      "102/102 [==============================] - 0s 769us/step - loss: 0.4576 - accuracy: 0.7828\n",
      "Epoch 77/100\n",
      "102/102 [==============================] - 0s 780us/step - loss: 0.4595 - accuracy: 0.7806\n",
      "Epoch 78/100\n",
      "102/102 [==============================] - 0s 798us/step - loss: 0.4586 - accuracy: 0.7812\n",
      "Epoch 79/100\n",
      "102/102 [==============================] - 0s 979us/step - loss: 0.4575 - accuracy: 0.7840\n",
      "Epoch 80/100\n",
      "102/102 [==============================] - 0s 861us/step - loss: 0.4581 - accuracy: 0.7754\n",
      "Epoch 81/100\n",
      "102/102 [==============================] - 0s 767us/step - loss: 0.4581 - accuracy: 0.7794\n",
      "Epoch 82/100\n",
      "102/102 [==============================] - 0s 757us/step - loss: 0.4580 - accuracy: 0.7815\n",
      "Epoch 83/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4577 - accuracy: 0.7772\n",
      "Epoch 84/100\n",
      "102/102 [==============================] - 0s 769us/step - loss: 0.4568 - accuracy: 0.7797\n",
      "Epoch 85/100\n",
      "102/102 [==============================] - 0s 790us/step - loss: 0.4583 - accuracy: 0.7800\n",
      "Epoch 86/100\n",
      "102/102 [==============================] - 0s 804us/step - loss: 0.4567 - accuracy: 0.7828\n",
      "Epoch 87/100\n",
      "102/102 [==============================] - 0s 747us/step - loss: 0.4556 - accuracy: 0.7806\n",
      "Epoch 88/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4560 - accuracy: 0.7846\n",
      "Epoch 89/100\n",
      "102/102 [==============================] - 0s 754us/step - loss: 0.4562 - accuracy: 0.7843\n",
      "Epoch 90/100\n",
      "102/102 [==============================] - 0s 787us/step - loss: 0.4556 - accuracy: 0.7815\n",
      "Epoch 91/100\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7815\n",
      "Epoch 92/100\n",
      "102/102 [==============================] - 0s 956us/step - loss: 0.4554 - accuracy: 0.7834\n",
      "Epoch 93/100\n",
      "102/102 [==============================] - 0s 873us/step - loss: 0.4540 - accuracy: 0.7849\n",
      "Epoch 94/100\n",
      "102/102 [==============================] - 0s 822us/step - loss: 0.4527 - accuracy: 0.7834\n",
      "Epoch 95/100\n",
      "102/102 [==============================] - 0s 745us/step - loss: 0.4576 - accuracy: 0.7794\n",
      "Epoch 96/100\n",
      "102/102 [==============================] - 0s 753us/step - loss: 0.4540 - accuracy: 0.7831\n",
      "Epoch 97/100\n",
      "102/102 [==============================] - 0s 746us/step - loss: 0.4529 - accuracy: 0.7846\n",
      "Epoch 98/100\n",
      "102/102 [==============================] - 0s 743us/step - loss: 0.4533 - accuracy: 0.7864\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 784us/step - loss: 0.4527 - accuracy: 0.7867\n",
      "Epoch 100/100\n",
      "102/102 [==============================] - 0s 741us/step - loss: 0.4552 - accuracy: 0.7818\n",
      "63/63 [==============================] - 0s 742us/step - loss: 0.4754 - accuracy: 0.7670\n",
      "[0.4753975570201874, 0.7670000195503235]\n",
      "63/63 [==============================] - 0s 701us/step\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84      1593\n",
      "           1       0.46      0.73      0.56       407\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.69      0.75      0.70      2000\n",
      "weighted avg       0.83      0.77      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0_maj, df2_class1_min, 3261, 3*1630)\n",
    "y_preds_en3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b188e12b-3cb6-4089-8c6d-c34f018185ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_preds_en3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "351dd860-1574-44f5-9fe6-3b289732ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_preds_en1.copy()\n",
    "for i in range(len(y_preds_en1)):\n",
    "    n_ones = y_preds_en1[i] + y_preds_en2[i] + y_preds_en3[i]\n",
    "    if n_ones > 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5da90bdb-cbe4-4c81-923d-f4511b0e7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84      1593\n",
      "           1       0.46      0.78      0.58       407\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.70      0.78      0.71      2000\n",
      "weighted avg       0.84      0.77      0.79      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
